```{r , echo=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(seqinr))
```

# On-demand R notebooks #

This interactive R notebook is running as a [Shiny][shiny] application
in R on a gizmo node that was snagged with grabcpu.

Hint: You can change things! Use Ctrl-Alt-i to insert an R code block,
use markdown syntax for text, and hit F4 to recompile.

## Loading data from silo

Since R is running on a gizmo node, we've got access to silo. This is
pretty neat, since that also means we have access to Galaxy output.

This is where our files live.

```{r }
database <- "/shared/silo_researcher/Matsen_F/MatsenGrp/data/galaxy-shapley/database"
```

Eventually stuff like this will be automated into boilerplate by
Galaxy:

```{r }
## "[Genus] Grouped-by-specimen classification (CSV)",csv,84726a17127220c7
by.specimen <- read.csv(file.path(database, "/files/004/dataset_4880.dat"), header=TRUE, as.is=TRUE)

## "1.TCA.454Reads.1000.fasta",fasta,2a0d57490303b027
reads <- read.fasta(file.path(database, "files/001/dataset_1351.dat"))
```

But first there needs to be a little glue layer in between that knows
how to load various kinds of data into R; I'm working on that now.

Also note the hex IDs in the strings above. Each Galaxy dataset is
assigned a global API ID in addition to a unique filename. So

Let's check that our data is there.

```{r }
head(by.specimen)
```

```{r }
str(reads[1])
```

Yay!

## Doing things

Now we can do whatever we want with our data (in any format R can be
made to understand). Like make pretty pictures using the microbiome
data we loaded earlier!

```{r , fig.height=9, fig.width=16}
ggplot(subset(by.specimen, tax_name=="Lactobacillus")[1:20,], aes(x=specimen, y=placements)) + geom_point(aes(color=placements, size=tally))
```

I should note that the microbiome dataset loaded above and used for
this plot was generated by the Galaxy workflow we developed when I was
testing it back in March. To be precise, it was generated Sun Mar 30
10:18:18 2014 (UTC). Here's what a Galaxy user can see about any
dataset in their history:

![A screenshot of dataset metadata.](http://i.imgur.com/ISMjKcx.png)

Galaxy knows a lot about the datasets it creates.

Anyway, for tools like Martin and Dan's, I think this kind of approach
makes a lot more sense than the standard submit-and-wait Galaxy
experience, and I think is more in line with what they wanted. They
can write their analyses in R and markdown, have access to the
pipeline outputs, and either

1. Use Shiny's [gorgeous interface][gallery] to make dynamic, user-friendly displays;
1. Generate a pretty ps or pdf, complete with timestamps and
   provenance, binary versions, etc.; or
1. Show a page like this and have a little playground to tweak
   settings or play with data.

And go click that link if you didn't. Seriously. At least look at
[this one][superzip].

## And more cool stuff!

In addition to presenting an editor, Shiny can also fetch text to
render from other sources:

* [runGist][rungist] -- Run a Shiny application from https://gist.github.com
* [runGitHub][rungithub] -- Run a Shiny application from a GitHub repository
* [runUrl][runurl] -- Run a Shiny application from a URL

There's also a standalone [Shiny server][server] capable of handling
more requests, available in both open-source and proprietary flavors,
and hosting available at [ShinyApps.io][hosted].

[shiny]: http://shiny.rstudio.com/
[rungist]: http://shiny.rstudio.com/reference/shiny/latest/runGist.html
[rungithub]: http://shiny.rstudio.com/reference/shiny/latest/runGitHub.html
[runurl]: http://shiny.rstudio.com/reference/shiny/latest/runUrl.html
[server]: http://shiny.rstudio.com/deploy/
[hosted]: http://www.rstudio.com/shiny/hosted/
[gallery]: http://shiny.rstudio.com/gallery/
[superzip]: http://shiny.rstudio.com/gallery/superzip-example.html
